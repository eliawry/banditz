#the allegory of the multi-armed bandit
the one-armed bandit, as you may know, is one of those spinnymajugger machines?
with the cherries? at las vegas?

whatever. you know.

a *slot machine*

why do people let me out of the house?

so for each of those bandits, you pay to play. and sometimes you lose money, but sometimes you win.

some cost more, some cost less. some pay more, some less. But the catch is, it's all probabilistic. one machine might pay off a million one time out of a hundred, and cost a penny to play. and it would take a while to figure out. you might never figure it out. you could almost say each machine has its own distribution of payoffs. but why would you?

anyway, let's say you have a bunch of pennies, and you have to spend them all on slots. you, my dear machine learning person allegory figure, have to figure out which lever to pull to maximize your payoff.

this is intimitely related to the idea of explore vs. exploit. If you have a 
machine you know gives small, steady payoffs, you might want to stick with it 
to be safe, especially if you've tried some of the other machines and found
them to have no payoff at all. but that might not be awesome. because what if 
the machine that had a zero payoff initially ends up having a really high payoff one time out of ten?

anyway, this thing is a casino with five machines, each of which
has its own distribition of payoffs. 

and yeah, for this it's like a step distribution of 0 or a lot

###future work

actually have distributions, and show people what they were and how they clicked, later. that could be pretty cool.